{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import json\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./previews'):\n",
    "    os.makedirs('./previews')\n",
    "if not os.path.exists('./checkpoints'):\n",
    "    os.makedirs('./checkpoints')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "n_words = 20 # 五言絕句\n",
    "n_class = 0\n",
    "n_noise = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poet_filter(x):\n",
    "    return len(''.join(x['paragraphs']))==20 and len(''.join(x['strains']))==20 # 五言絕句，不包含逗號句號分號\n",
    "\n",
    "def poet_preprocess(x): # 去除標點符號\n",
    "    x['paragraphs'] = ''.join(filter(lambda x: x!='，' and x!='。' and x!='；' ,list(''.join(x['paragraphs']))))\n",
    "    x['strains'] = ''.join(filter(lambda x: x!='，' and x!='。' and x!='；' , list(''.join(x['strains']))))\n",
    "    return x\n",
    "\n",
    "def poet_data_reader(search='./chinese-poetry-master/json/poet.song.*.json', filters=lambda x: True):\n",
    "    file_list = glob.glob(search)\n",
    "    data = []\n",
    "    for fname in file_list:\n",
    "        with open(fname, 'r') as fp:\n",
    "            data += filter(poet_filter, map(poet_preprocess , json.loads(fp.read())))\n",
    "    return data\n",
    "def gen_dict(poets):\n",
    "    char_set = dict()\n",
    "    char_set_inv = dict()\n",
    "    for poet in poets:\n",
    "        context = list(poet['paragraphs'])\n",
    "        for c in filter(lambda x: x not in char_set, context):\n",
    "            l = len(char_set)\n",
    "            char_set[c] = l\n",
    "            char_set_inv[l] = c\n",
    "    return char_set, char_set_inv\n",
    "def encode_context(context, charset):\n",
    "    def f(x):\n",
    "        return charset[x] if x in charset else 0\n",
    "    return list(map(f, list(context)))\n",
    "def one_hot(x, n_class):\n",
    "    ohe = np.zeros((len(x), n_class), dtype=np.uint8)\n",
    "    ohe[np.arange(len(x)), x] = 1\n",
    "    return ohe\n",
    "def str2ohe(x, charset):\n",
    "    return one_hot(encode_context(x, charset), len(charset))\n",
    "def ohe2str(x, charset_inv):\n",
    "    x = np.argmax(x,axis=-1)\n",
    "    return ''.join(list(map(lambda a: charset_inv[a], list(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = poet_data_reader(search='./chinese-poetry-master/json/poet.song.*.json', filters=poet_filter)\n",
    "charset, charset_inv = gen_dict(raw_data)\n",
    "strainset = {'平': 0, '仄': 1}\n",
    "with open('./charset.json', 'w') as fp:\n",
    "    fp.write(json.dumps(charset))\n",
    "with open('./strainset.json', 'w') as fp:\n",
    "    fp.write(json.dumps(strainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13260, 5798, 20])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ohe = torch.from_numpy(np.asarray(list(map(lambda x: str2ohe(x['paragraphs'], charset), raw_data)), dtype=np.float32).transpose(0,2,1))\n",
    "data_ohe = data_ohe * 2 - 1 # [0, 1] -> [-1, +1]\n",
    "data_ohe.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13260, 2, 20])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_ohe = torch.from_numpy(np.asarray(list(map(lambda x: str2ohe(x['strains'], strainset), raw_data)), dtype=np.float32).transpose(0,2,1))\n",
    "label_ohe = label_ohe * 2 - 1 # [0, 1] -> [-1, +1]\n",
    "label_ohe.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = data_ohe.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "poet_dataset = torch.utils.data.TensorDataset(data_ohe, label_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "        poet_dataset,\n",
    "        batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "def inf_data_gen():\n",
    "    while True:\n",
    "        for data, label in data_loader:\n",
    "            yield data\n",
    "gen = inf_data_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0, 0.001)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0, 0.001)\n",
    "\n",
    "def wgan_div_gp(real, d_real, device, p):\n",
    "    ones_real = torch.ones_like(d_real, device=device, requires_grad=False)\n",
    "    gradients_real = torch.autograd.grad(\n",
    "            outputs=d_real,\n",
    "            inputs=real,\n",
    "            grad_outputs=ones_real,\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True,\n",
    "        )[0]\n",
    "    return gradients_real.view(gradients_real.size(0),-1).pow(2).sum(1)**(p/2) \n",
    "\n",
    "class C(nn.Module):\n",
    "    def __init__(self, n_words=20, n_class=5000):\n",
    "        super(C, self).__init__()\n",
    "        self.n_words = n_words\n",
    "        self.n_class = n_class\n",
    "        self.net = nn.Sequential(*[\n",
    "            nn.Conv1d(self.n_class, 512, kernel_size=1, padding=0, bias=False), # embedding\n",
    "            nn.Conv1d(512, 64, kernel_size=3, stride=1, padding=1, bias=False), # 10\n",
    "            nn.InstanceNorm1d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv1d(64, 128, kernel_size=5, stride=2, padding=2, bias=False), # 10\n",
    "            nn.InstanceNorm1d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1, bias=False), # 10\n",
    "            nn.InstanceNorm1d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1, bias=False), # 10\n",
    "            nn.InstanceNorm1d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv1d(256, 512, kernel_size=3, stride=2, padding=1, bias=False), # 5\n",
    "            nn.InstanceNorm1d(512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv1d(512, 1, kernel_size=n_words//4, padding=0, bias=False)\n",
    "        ])\n",
    "        self.net.apply(weights_init)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = x.view(x.size(0),1)\n",
    "        return x\n",
    "\n",
    "class G(nn.Module):\n",
    "    def __init__(self, n_words=20, n_class=5000, n_noise=128):\n",
    "        super(G, self).__init__()\n",
    "        self.n_words = n_words\n",
    "        self.n_class = n_class\n",
    "        self.n_noise = n_noise\n",
    "        self.fc1 = nn.Linear(self.n_noise, 64*(self.n_words//4), bias=False)\n",
    "        weights_init(self.fc1)\n",
    "        self.net = nn.Sequential(*[\n",
    "            nn.ConvTranspose1d(64, 128, kernel_size=4, stride=2, padding=1, bias=False), # 10\n",
    "            nn.InstanceNorm1d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.ConvTranspose1d(128, 256, kernel_size=4, stride=2, padding=1, bias=False), # 20\n",
    "            nn.InstanceNorm1d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv1d(256, 512, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "            nn.InstanceNorm1d(512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv1d(512, self.n_class, kernel_size=1, padding=0, bias=False),\n",
    "        ])\n",
    "        self.net.apply(weights_init)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = x.view(x.size(0), 64, self.n_words//4)\n",
    "        x = self.net(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3 # debug!!!\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "G_net = G(n_words, n_class, n_noise).to(device)\n",
    "C_net = C(n_words, n_class).to(device)\n",
    "opt_C = optim.Adam(C_net.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "opt_G = optim.Adam(G_net.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4b3d50a9fa483fa7820d28d75bf514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500/50000] G: 9.5918, D:-19.5586 -- elapsed_G: 0.0217s -- elapsed_D: 1.7426s\n",
      "[1000/50000] G: -1.7624, D:-0.8696 -- elapsed_G: 0.0215s -- elapsed_D: 1.6139s\n",
      "[1500/50000] G: -0.7173, D:-0.0249 -- elapsed_G: 0.0216s -- elapsed_D: 1.6110s\n",
      "[2000/50000] G: -3.2163, D:-0.0150 -- elapsed_G: 0.0216s -- elapsed_D: 1.6099s\n",
      "[2500/50000] G: 0.5349, D:0.0098 -- elapsed_G: 0.0211s -- elapsed_D: 1.5801s\n",
      "[3000/50000] G: -2.2498, D:-0.0135 -- elapsed_G: 0.0210s -- elapsed_D: 1.5802s\n",
      "[3500/50000] G: -1.1548, D:-0.0000 -- elapsed_G: 0.0211s -- elapsed_D: 1.5820s\n",
      "[4000/50000] G: 0.8413, D:-0.0045 -- elapsed_G: 0.0210s -- elapsed_D: 1.5817s\n",
      "[4500/50000] G: -40.9502, D:-0.4438 -- elapsed_G: 0.0210s -- elapsed_D: 1.5801s\n",
      "[5000/50000] G: -32.1468, D:-0.4804 -- elapsed_G: 0.0213s -- elapsed_D: 1.5830s\n",
      "[5500/50000] G: -21.4478, D:0.0362 -- elapsed_G: 0.0211s -- elapsed_D: 1.5826s\n",
      "[6000/50000] G: -21.5161, D:-0.6145 -- elapsed_G: 0.0210s -- elapsed_D: 1.5816s\n",
      "[6500/50000] G: -21.8664, D:-0.0305 -- elapsed_G: 0.0210s -- elapsed_D: 1.5808s\n",
      "[7000/50000] G: -25.4763, D:-0.3348 -- elapsed_G: 0.0212s -- elapsed_D: 1.5828s\n",
      "[7500/50000] G: -22.6681, D:-0.6599 -- elapsed_G: 0.0210s -- elapsed_D: 1.5818s\n",
      "[8000/50000] G: -15.1018, D:-0.0159 -- elapsed_G: 0.0210s -- elapsed_D: 1.5864s\n",
      "[8500/50000] G: -11.3276, D:-0.4321 -- elapsed_G: 0.0211s -- elapsed_D: 1.5814s\n",
      "[9000/50000] G: -12.4400, D:-0.5807 -- elapsed_G: 0.0213s -- elapsed_D: 1.6757s\n",
      "[9500/50000] G: -12.1966, D:-0.6127 -- elapsed_G: 0.0210s -- elapsed_D: 1.5820s\n",
      "[10000/50000] G: -10.6371, D:-0.5514 -- elapsed_G: 0.0211s -- elapsed_D: 1.5785s\n",
      "[10500/50000] G: -8.6469, D:-0.5349 -- elapsed_G: 0.0213s -- elapsed_D: 1.5843s\n",
      "[11000/50000] G: -9.5574, D:-0.3729 -- elapsed_G: 0.0211s -- elapsed_D: 1.5805s\n",
      "[11500/50000] G: -6.0172, D:-0.3475 -- elapsed_G: 0.0211s -- elapsed_D: 1.5811s\n",
      "[12000/50000] G: -7.2980, D:-0.3601 -- elapsed_G: 0.0211s -- elapsed_D: 1.5845s\n",
      "[12500/50000] G: -6.8317, D:-0.0907 -- elapsed_G: 0.0211s -- elapsed_D: 1.5770s\n",
      "[13000/50000] G: -5.0796, D:-0.3563 -- elapsed_G: 0.0210s -- elapsed_D: 1.5784s\n",
      "[13500/50000] G: -1.8072, D:-0.2862 -- elapsed_G: 0.0212s -- elapsed_D: 1.5811s\n",
      "[14000/50000] G: -3.9516, D:-0.3577 -- elapsed_G: 0.0210s -- elapsed_D: 1.5814s\n",
      "[14500/50000] G: -4.1322, D:-0.3056 -- elapsed_G: 0.0210s -- elapsed_D: 1.5837s\n",
      "[15000/50000] G: -5.2080, D:-0.3004 -- elapsed_G: 0.0210s -- elapsed_D: 1.5794s\n",
      "[15500/50000] G: -4.1631, D:-0.3546 -- elapsed_G: 0.0211s -- elapsed_D: 1.5806s\n",
      "[16000/50000] G: -3.7010, D:-0.2915 -- elapsed_G: 0.0210s -- elapsed_D: 1.5794s\n",
      "[16500/50000] G: -4.6685, D:-0.2676 -- elapsed_G: 0.0212s -- elapsed_D: 1.5823s\n",
      "[17000/50000] G: -3.6621, D:-0.3039 -- elapsed_G: 0.0210s -- elapsed_D: 1.5806s\n",
      "[17500/50000] G: -4.1320, D:0.1976 -- elapsed_G: 0.0211s -- elapsed_D: 1.6671s\n",
      "[18000/50000] G: -5.2170, D:-0.0227 -- elapsed_G: 0.0212s -- elapsed_D: 1.5830s\n",
      "[18500/50000] G: -4.5538, D:-5.2776 -- elapsed_G: 0.0210s -- elapsed_D: 1.5797s\n",
      "[19000/50000] G: -10.3801, D:0.0297 -- elapsed_G: 0.0211s -- elapsed_D: 1.5782s\n",
      "[19500/50000] G: -7.9270, D:0.0807 -- elapsed_G: 0.0212s -- elapsed_D: 1.5804s\n",
      "[20000/50000] G: -26.4726, D:2.0520 -- elapsed_G: 0.0211s -- elapsed_D: 1.5820s\n",
      "[20500/50000] G: -25.5158, D:-0.0833 -- elapsed_G: 0.0211s -- elapsed_D: 1.5797s\n",
      "[21000/50000] G: -7.0130, D:-7.1012 -- elapsed_G: 0.0211s -- elapsed_D: 1.5761s\n",
      "[21500/50000] G: -30.5145, D:-11.4064 -- elapsed_G: 0.0211s -- elapsed_D: 1.5825s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d54480e1caa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_loss_real\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md_loss_fake\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md_gp_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mopt_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0md_loss_mean\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0md_loss_mean\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0md_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mD_update_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "iterations = 50000\n",
    "preview_iter = 500\n",
    "preview_n = 8\n",
    "d_iter = 15\n",
    "std = 1.0\n",
    "lambda_1 , lambda_2 = 10 , 0.2\n",
    "M = 0.05\n",
    "k, p = 2, 6\n",
    "\n",
    "samples_preview = torch.randn(preview_n, n_noise).clamp(-2,2) * std\n",
    "\n",
    "for ite in tqdm_notebook(range(1, iterations+1)):\n",
    "    start_train_ts = time.time()\n",
    "    # train D:\n",
    "    G_net.eval()\n",
    "    C_net.train()\n",
    "    d_loss_mean = 0.0\n",
    "    g_loss_mean = 0.0\n",
    "    for _ in range(d_iter):\n",
    "        opt_C.zero_grad()\n",
    "        real = next(gen).to(device).requires_grad_(True)\n",
    "        sample = torch.randn(real.size(0), n_noise, device=device).clamp(-2,2) * std\n",
    "        with torch.no_grad():\n",
    "            fake   = G_net(sample).detach() # not to touch G_net\n",
    "        fake.requires_grad_(True)\n",
    "        d_real = C_net(real)\n",
    "        d_fake = C_net(fake)\n",
    "        d_loss_real = d_real.mean()\n",
    "        d_loss_real.backward(retain_graph=True)\n",
    "        d_loss_fake = -d_fake.mean()\n",
    "        d_loss_fake.backward(retain_graph=True)\n",
    "        d_real_gp = wgan_div_gp(real, d_real, device, p)\n",
    "        d_fake_gp = wgan_div_gp(fake, d_fake, device, p)\n",
    "        d_gp_loss = (d_real_gp+d_fake_gp).mean() * k / 2\n",
    "        d_gp_loss.backward(retain_graph=True)\n",
    "        d_loss = d_loss_real + d_loss_fake + d_gp_loss\n",
    "        opt_C.step()\n",
    "        d_loss_mean += d_loss.item()\n",
    "    d_loss_mean /= d_iter\n",
    "    D_update_ts = time.time()\n",
    "    # train G:\n",
    "    G_net.train()\n",
    "    C_net.train() # activate Discriminator's Dropout \n",
    "    opt_G.zero_grad()\n",
    "    sample = torch.randn(batch_size, n_noise, device=device).clamp(-2,2) * std\n",
    "    generated = G_net(sample)\n",
    "    g_loss = C_net(generated).mean()\n",
    "    g_loss.backward()\n",
    "    opt_G.step()\n",
    "    g_loss_mean = g_loss.mean().item()\n",
    "    G_update_ts = time.time()\n",
    "    if ite%preview_iter==0:\n",
    "        print('[{}/{}] G: {:.4f}, D:{:.4f} -- elapsed_G: {:.4f}s -- elapsed_D: {:.4f}s'.format(ite, iterations, g_loss_mean, d_loss_mean, (G_update_ts-D_update_ts), (D_update_ts-start_train_ts) ))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            G_net.eval() # evaluation state\n",
    "            generated = G_net(samples_preview.to(device)).detach().cpu().numpy()\n",
    "            generated = generated.transpose(0, 2, 1) # (?, 20, 5xxx)\n",
    "            recovered = list(map(lambda x: ohe2str(x, charset_inv), generated))\n",
    "            with open('./previews/iter-{:d}.txt'.format(ite), 'w') as fp:\n",
    "                for poet in recovered:\n",
    "                    fp.write(poet[:5]+'，')\n",
    "                    fp.write(poet[5:10]+'。')\n",
    "                    fp.write(poet[10:15]+'，')\n",
    "                    fp.write(poet[15:20]+'。')\n",
    "                    fp.write('\\n')\n",
    "                \n",
    "        \n",
    "        torch.save(G_net.state_dict(), './checkpoints/iter-{:d}-G.ckpt'.format(ite))\n",
    "        torch.save(C_net.state_dict(), './checkpoints/iter-{:d}-D.ckpt'.format(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
